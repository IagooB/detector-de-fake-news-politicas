{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar los conjuntos de datos\n",
    "verificat = pd.read_csv(\"datos_iniciales/verificat.csv\")\n",
    "newtral = pd.read_csv(\"datos_iniciales/noticias_newtral.csv\")\n",
    "efe = pd.read_csv(\"datos_iniciales/noticias_efe.csv\")\n",
    "meneame = pd.read_csv(\"datos_iniciales/noticias_meneame.csv\")\n",
    "\n",
    "# Filtrar datos irrelevantes en el dataset de Newtral\n",
    "newtral = newtral[~newtral[\"Contenido\"].str.contains(\"Este vídeo|Esta imagen\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:31:05.076634Z",
     "start_time": "2024-12-17T12:31:04.324247Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Limpieza de texto en el contenido de Newtral\n",
    "newtral['Contenido'] = newtral['Contenido'].str.replace(r'He leído y acepto laPolítica de privacidad\\*', '', regex=True)\n",
    "newtral['Contenido'] = newtral['Contenido'].str.replace(r'Δ|Interesa\\n|\\n|\\s{2,}', '', regex=True)\n",
    "\n",
    "# Filtrar noticias de Menéame con menos de 60 meneos\n",
    "meneame = meneame[meneame['Meneos'] >= 60]\n",
    "\n",
    "# Renombrar columnas para unificar los datasets\n",
    "efe = efe.rename(columns={'Título': 'Título', 'Fecha': 'Fecha', 'Contenido': 'Contenido', 'URL': 'URL'})\n",
    "meneame = meneame[['Título', 'Fecha', 'Contenido', 'URL']]\n",
    "newtral = newtral.rename(columns={'Titular': 'Título'})[['Título', 'Fecha', 'Contenido']]\n",
    "verificat = verificat.rename(columns={'Titular': 'Título'})[['Título', 'Fecha', 'Contenido']]\n",
    "\n",
    "# Agregar columna de fuente para identificar el origen de los datos\n",
    "efe['Fuente'] = 'EFE'\n",
    "meneame['Fuente'] = 'Meneame'\n",
    "newtral['Fuente'] = 'Newtral'\n",
    "verificat['Fuente'] = 'Verificat'\n",
    "\n",
    "# Combinar todos los datasets en uno unificado\n",
    "datasets = [efe, meneame, newtral, verificat]\n",
    "unified_dataset = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "# Asignar índices únicos y establecer el nuevo índice\n",
    "unified_dataset[\"Numero\"] = range(1, len(unified_dataset) + 1)\n",
    "unified_dataset = unified_dataset.set_index([\"Numero\"])\n",
    "\n",
    "# Copiar el dataset para análisis posterior\n",
    "data = unified_dataset.copy()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Visualizar el número de noticias por fuente\n",
    "medio_counts = data['Fuente'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "medio_counts.plot(kind='bar')\n",
    "plt.xlabel('Fuente')\n",
    "plt.ylabel('Número de noticias')\n",
    "plt.title('Reparto de noticias por Fuente')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcular el recuento de palabras en las noticias\n",
    "data['word_count'] = data['Contenido'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Crear histograma del recuento de palabras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data['word_count'], bins=40, edgecolor='black')\n",
    "plt.xlabel('Número de palabras en el contenido')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma del recuento de palabras en el contenido')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Filtrar noticias con menos de 2500 palabras\n",
    "data = data[data['word_count'] < 2500]\n",
    "\n",
    "# Cargar y procesar datasets adicionales\n",
    "fake_tweets = pd.read_csv(\"tweets_falsos/tweets_falsos_156.csv\").drop_duplicates().dropna()\n",
    "fake_news = pd.read_csv(\"noticias_falsas_cleaned.csv\").drop_duplicates().dropna()\n",
    "\n",
    "# Visualizar distribución de palabras en noticias falsas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(fake_news['Palabras'], bins=40, edgecolor='black')\n",
    "plt.xlabel('Número de palabras en el contenido')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma del recuento de palabras en noticias falsas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizar distribución de palabras en tweets falsos\n",
    "fake_tweets['word_count'] = fake_tweets['Tweet'].apply(lambda x: len(str(x).split()))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(fake_tweets['word_count'], bins=40, edgecolor='black')\n",
    "plt.xlabel('Número de palabras en los tweets')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma del recuento de palabras en tweets falsos')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
